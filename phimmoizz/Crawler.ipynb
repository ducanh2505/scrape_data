{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests-html in /home/tuhp/.local/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.10.0)\n",
      "Collecting pyppdf\n",
      "  Downloading pyppdf-0.1.2.tar.gz (26 kB)\n",
      "Requirement already satisfied: parse in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (1.18.0)\n",
      "Requirement already satisfied: fake-useragent in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (0.1.11)\n",
      "Requirement already satisfied: requests in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (2.24.0)\n",
      "Requirement already satisfied: w3lib in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (1.22.0)\n",
      "Requirement already satisfied: pyquery in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: bs4 in /home/tuhp/.local/lib/python3.6/site-packages (from requests-html->-r requirements.txt (line 1)) (0.0.1)\n",
      "Requirement already satisfied: certifi in /home/tuhp/.local/lib/python3.6/site-packages (from pyppdf->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting litereval>=0.0.9\n",
      "  Downloading litereval-0.0.11.tar.gz (20 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/tuhp/.local/lib/python3.6/site-packages (from requests->requests-html->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/tuhp/.local/lib/python3.6/site-packages (from requests->requests-html->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/tuhp/.local/lib/python3.6/site-packages (from requests->requests-html->-r requirements.txt (line 1)) (1.25.11)\n",
      "Requirement already satisfied: six>=1.4.1 in /home/tuhp/.local/lib/python3.6/site-packages (from w3lib->requests-html->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: lxml>=2.1 in /home/tuhp/.local/lib/python3.6/site-packages (from pyquery->requests-html->-r requirements.txt (line 1)) (4.5.2)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /home/tuhp/.local/lib/python3.6/site-packages (from pyquery->requests-html->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: websockets<9.0,>=8.1 in /home/tuhp/.local/lib/python3.6/site-packages (from pyppeteer>=0.0.14->requests-html->-r requirements.txt (line 1)) (8.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /home/tuhp/.local/lib/python3.6/site-packages (from pyppeteer>=0.0.14->requests-html->-r requirements.txt (line 1)) (4.50.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /home/tuhp/.local/lib/python3.6/site-packages (from pyppeteer>=0.0.14->requests-html->-r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: pyee<8.0.0,>=7.0.1 in /home/tuhp/.local/lib/python3.6/site-packages (from pyppeteer>=0.0.14->requests-html->-r requirements.txt (line 1)) (7.0.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/tuhp/.local/lib/python3.6/site-packages (from bs4->requests-html->-r requirements.txt (line 1)) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/tuhp/.local/lib/python3.6/site-packages (from beautifulsoup4->bs4->requests-html->-r requirements.txt (line 1)) (2.0.1)\n",
      "Building wheels for collected packages: pyppdf, litereval\n",
      "  Building wheel for pyppdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyppdf: filename=pyppdf-0.1.2-py3-none-any.whl size=14088 sha256=98c1eb0b0fe8984419daebd28e2ffec605fc205a41ad1a5ca85cf0ca7d4ad8e2\n",
      "  Stored in directory: /home/tuhp/.cache/pip/wheels/eb/00/28/373d9d5e10dd2f5ef1a7fba3735b26f9f7f57be23e72c3f570\n",
      "  Building wheel for litereval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for litereval: filename=litereval-0.0.11-py3-none-any.whl size=7057 sha256=2bfd631a7f4f0f8ee9dfc0ec52749debe4ce22befeffc6b12f8e2dbd1d6356f5\n",
      "  Stored in directory: /home/tuhp/.cache/pip/wheels/69/6b/e8/10ae8c15ecac33379af3198cd008df6f1196d384e209cae5a6\n",
      "Successfully built pyppdf litereval\n",
      "Installing collected packages: click, psutil, litereval, pyppdf\n",
      "Successfully installed click-7.1.2 litereval-0.0.11 psutil-5.8.0 pyppdf-0.1.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ! pip install -r requirements.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from requests_html import HTMLSession\n",
    "from requests_html import AsyncHTMLSession\n",
    "import pyppdf.patch_pyppeteer\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "\n",
    "\n",
    "# declare global varibles \n",
    "SESSION = HTMLSession()\n",
    "\n",
    "asession = AsyncHTMLSession()\n",
    "HOME = 'http://www.phimmoizz.net/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype Functions:\n",
    "* `get_movies_on_page(links,session = SESSION)` : return list of movie urls from link:\n",
    "* `get_data_from_movie(url,session=SESSION)`:  return information of movie in url; return type: dictionary \n",
    "* `links_crawler(output='links.txt')`: crawl all movie links on http://www.phimmoizz.net/phim-le/ (while crawling, append links to file output)\n",
    "* `movie_data_crawler(input='links.txt')`: crawl data of movies from file input contain links of movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.phimmoizz.net/phim/thong-long-ma-2-12027/',\n",
       " 'http://www.phimmoizz.net/phim/phim-doraemon-nobita-va-nhung-ban-khung-long-moi-9271/',\n",
       " 'http://www.phimmoizz.net/phim/intersection-12028/',\n",
       " 'http://www.phimmoizz.net/phim/cung-lam-anh-hung-12023/',\n",
       " 'http://www.phimmoizz.net/phim/soul-9807/',\n",
       " 'http://www.phimmoizz.net/phim/them-mot-chau-nua-nhe-12022/',\n",
       " 'http://www.phimmoizz.net/phim/ky-nghi-le-vang-ky-nghi-nho-doi-12021/',\n",
       " 'http://www.phimmoizz.net/phim/ak-vs-ak-12024/',\n",
       " 'http://www.phimmoizz.net/phim/nu-than-chien-binh-1984-9573/',\n",
       " 'http://www.phimmoizz.net/phim/doi-quan-mot-nguoi-12015/',\n",
       " 'http://www.phimmoizz.net/phim/hon-ca-mot-gia-dinh-me-bau-sieu-ngau-12012/',\n",
       " 'http://www.phimmoizz.net/phim/ta-ma-va-bong-toi-12005/',\n",
       " 'http://www.phimmoizz.net/phim/lap-lanh-troi-dem-12008/',\n",
       " 'http://www.phimmoizz.net/phim/bien-nien-su-giang-sinh-phan-hai-11879/',\n",
       " 'http://www.phimmoizz.net/phim/bien-nien-su-giang-sinh-8041/',\n",
       " 'http://www.phimmoizz.net/phim/cai-ten-khac-sau-trong-tim-nguoi-12009/',\n",
       " 'http://www.phimmoizz.net/phim/ariana-grande-excuse-me-i-love-you-12010/',\n",
       " 'http://www.phimmoizz.net/phim/xich-ho-thu-sinh-11992/',\n",
       " 'http://www.phimmoizz.net/phim/tho-san-dem-11996/',\n",
       " 'http://www.phimmoizz.net/phim/chuyen-xe-ba-dao-11994/',\n",
       " 'http://www.phimmoizz.net/phim/song-trung-11993/',\n",
       " 'http://www.phimmoizz.net/phim/ngon-tu-trong-phong-tam-11988/',\n",
       " 'http://www.phimmoizz.net/phim/nu-than-chien-binh-wonder-woman-i1-4012/',\n",
       " 'http://www.phimmoizz.net/phim/hay-de-ho-giai-bay-11986/',\n",
       " 'http://www.phimmoizz.net/phim/anh-hung-hamilton-11982/',\n",
       " 'http://www.phimmoizz.net/phim/vo-gian-hanh-gia-sinh-tu-tiem-hanh-11987/',\n",
       " 'http://www.phimmoizz.net/phim/bao-thu-11984/',\n",
       " 'http://www.phimmoizz.net/phim/i-m-your-woman-11981/',\n",
       " 'http://www.phimmoizz.net/phim/gia-dinh-croods-ky-nguyen-moi-11980/',\n",
       " 'http://www.phimmoizz.net/phim/soi-lang-thang-11977/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_movies(link,session = SESSION):\n",
    "    r = session.get(link)\n",
    "    return [HOME + e.attrs['href'] for e in r.html.find('.list-movie')[0].find('a') ]\n",
    "\n",
    "# exammple \n",
    "get_movies('http://www.phimmoizz.net/phim-le/page-1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_json('data.json',lines=True).to_csv('data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMDb': '4.3',\n",
       " 'IMDb_votes': '166',\n",
       " 'director': 'Liming Li,',\n",
       " 'nations': 'Trung Quốc,',\n",
       " 'relase': '23/12/2019',\n",
       " 'duration': '84',\n",
       " 'quality': 'Bản đẹp',\n",
       " 'resolution': 'HD 720p',\n",
       " 'language': 'Thuyết minh',\n",
       " 'genres': 'Phim hành động, Phim võ thuật, Phim hồi hộp-Gây cấn, Phim thuyết minh, Phim lẻ',\n",
       " 'company': 'Chưa rõ',\n",
       " 'vietnamese_name': 'Diệp Vấn: Bậc Thầy Võ Thuật',\n",
       " 'name': 'Ip Man: Kung Fu Master',\n",
       " 'year': '2019',\n",
       " 'id': '11979',\n",
       " 'star': '5.96',\n",
       " 'film_content': 'IP MAN: KUNG FU MASTER quay trở lại những ngày đầu của Ip trước Cách mạng Cộng sản năm 1949. Ip, do Dennis To thể hiện lần thứ ba với vai võ sĩ nổi tiếng kèm cặp Lý Tiểu Long, lúc đó là đội trưởng cảnh sát bị buộc tội giết người của một tên cướp tàn nhẫn nhưng danh dự, và được nhắm mục tiêu báo thù bởi đứa con gái nguy hiểm của mình. Bị buộc phải từ bỏ lực lượng, Ip cũng sớm phải đối mặt với sự xuất hiện của quân đội Nhật Bản tại Quảng Châu.Trong thời gian làm đội trưởng cảnh sát ở Phật Sơn, Ip Man là mục tiêu của một băng đảng xã hội đen báo thù ngay khi quân đội Nhật Bản xâm lược khu vực',\n",
       " 'actors': 'Yu-Hang To, Michael Wong, Wanliruo Xin, Dongfeng Yue'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_from_movie(url,session=SESSION):\n",
    "    '''\n",
    "        return dictionary attributes:\n",
    "                name : str\n",
    "                ,id: str\n",
    "                ,IMDb : float\n",
    "                ,IMDb_votes : int\n",
    "                ,AW: float\n",
    "                ,AW_votes: int\n",
    "                ,duration: int (minutes)\n",
    "                ,year : int\n",
    "                ,relase : datetime\n",
    "                ,nations : str\n",
    "                ,quality : str\n",
    "                ,resolution: str\n",
    "                ,language: str\n",
    "                ,genres: str\n",
    "                ,company: str\n",
    "                ,star: int\n",
    "                ,star_votes: int\n",
    "                ,recommendations : list ID (class of model)\n",
    "    '''\n",
    "\n",
    "    mapping_name = {\n",
    "        'Thể loại': 'genres',\n",
    "        'Ngôn ngữ': 'language',\n",
    "        'Độ phân giải':'resolution',\n",
    "#         '': 'star',\n",
    "#         '': 'star_votes',\n",
    "        'Thời lượng': 'duration',\n",
    "        'Chất lượng': 'quality',\n",
    "        'Quốc gia': 'nations',\n",
    "        'Công ty SX': 'company',\n",
    "        'Ngày phát hành': 'relase',\n",
    "        'Đạo diễn':'director',\n",
    "#         '': 'recommendations',\n",
    "#         '': 'AW_votes',\n",
    "#         '': 'AW',\n",
    "        'Điểm IMDb': 'IMDb',\n",
    "        'Số người đánh giá': 'IMDb_votes',\n",
    "    }\n",
    "    r =  session.get(url)    \n",
    "    result = {}\n",
    "    \n",
    "    for attr, info in zip(r.html.find('.movie-dt'), r.html.find('.movie-dd')):\n",
    "        if attr.text[:-1] not in mapping_name.keys():\n",
    "            continue\n",
    "        result[mapping_name[attr.text[:-1]]] = info.text.strip(' ()')\n",
    "    result['vietnamese_name'] = r.html.find('.title-1')[0].text\n",
    "    result['name'] = r.html.find('.title-2')[0].text\n",
    "    result['year'] = r.html.find('.title-year')[0].text.strip(' ()')\n",
    "    \n",
    "    result['id'] = r.url.strip('/').split('-')[-1]\n",
    "    \n",
    "    result['star'] = r.html.find('#score_current')[0].attrs['value']\n",
    "    #result['star_votes'] = r.html.find('.rating-text')[0].text.split()[-2]\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    if 'IMDb_votes' in result.keys():\n",
    "        result['IMDb_votes'] = re.sub('[^\\d]+', '', str(result['IMDb_votes']))\n",
    "    else:\n",
    "        result['IMDb_votes'] = None\n",
    "    result['duration'] = re.sub('[^\\d]+', '', str(result['duration']))\n",
    "    \n",
    "    result['film_content'] = r.html.find('#film-content')[0].text\n",
    "    result['actors'] = \", \".join([ actor.text for actor in r.html.find('.actor-name-a')])\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "# example \n",
    "url = 'http://www.phimmoizz.net/phim/diep-van-bac-thay-vo-thuat-11979/'\n",
    "get_data_from_movie(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_crawler(output='links.txt', session=SESSION):\n",
    "    finish = False\n",
    "    page = 1 \n",
    "    while  not finish :\n",
    "        link = HOME+ '/phim-le/page-{}'.format(page) + '.html'\n",
    "        r = session.get(link)\n",
    "        list_movie = r.html.find('.list-movie',first=True).find('a')\n",
    "        if len(list_movie) > 0:  \n",
    "            # periodly print progess \n",
    "            if page % 50 == 0 :\n",
    "                print('Current page: {}'.format(page))\n",
    "            \n",
    "            # write to file\n",
    "            with open(output,'a') as f:\n",
    "                f.writelines([ HOME + e.attrs['href'] + '\\n' for e in list_movie])\n",
    "            page +=1\n",
    "            \n",
    "        else:\n",
    "            print('Total page: {}'.format(page))\n",
    "            finish = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current page: 50\n",
      "Current page: 100\n",
      "Current page: 150\n",
      "Total page: 200\n"
     ]
    }
   ],
   "source": [
    "links_crawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_data_crawler(input='links.txt', session=SESSION):\n",
    "    film_links = []\n",
    "    with open(input, 'r') as f:\n",
    "        film_links = f.readlines()\n",
    "    film_links = [link[:-1] for link in film_links] # drop \\n\n",
    "    flag = False\n",
    "    film_data = []\n",
    "    par = tqdm(enumerate(film_links),total =len(film_links))\n",
    "    csv_columns = list(get_data_from_movie(film_links[0]).keys())\n",
    "    with open('data.csv', 'a+') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "    \n",
    "    for index,link in par: \n",
    "        try :\n",
    "            film_dict = get_data_from_movie(link)            \n",
    "            pd.DataFrame(film_dict,columns =csv_columns,index=[index]).to_csv('data.csv',mode='a+',header=False,index=False)\n",
    "        except:\n",
    "            flag = True\n",
    "            with open('errors.txt','a+') as f:\n",
    "                f.write('{}\\n'.format(index))\n",
    "    print(\"Try scrawl data from links that get error\")\n",
    "    if flag :\n",
    "        with open('errors.txt','r') as f:\n",
    "            error = f.readlines()\n",
    "            index = [int(e[:-1]) for e in error]\n",
    "            for i in index: \n",
    "                pd.DataFrame(film_dict,columns =csv_columns,index=[i]).to_csv('data.csv',mode='a+',header=False,index=False)\n",
    "    return 0\n",
    "    \n",
    "        \n",
    "#     print(film_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f3819110f245d1806ac3177f36f0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5964.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Try scrawl data from links that get error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data_crawler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 17 fields in line 216, saw 18\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-70e2bf25f37a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2145\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2146\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 17 fields in line 216, saw 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.director.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df.genres.apply(lambda x:x.split(', ')).explode().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = np.zeros((len(df),len(genres)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = []\n",
    "for i,g in df.genres.apply(lambda x:x.split(', ')).explode().apply(lambda x: genres.index(x)).items():\n",
    "  labels[i][g] = 1\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.DataFrame(labels,columns =genres )], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['genres'],inplace = True,axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   The Teacher (My Soul Is Made Of Love)\n",
       "1                                             Last Letter\n",
       "6                                                Ammonite\n",
       "10                  The Teacher (My Soul Is Made Of Love)\n",
       "11                                            Last Letter\n",
       "                              ...                        \n",
       "5586                                              Titanic\n",
       "5619                          You Are the Apple of My Eye\n",
       "5686                                       The Best Offer\n",
       "5877                                       A Werewolf Boy\n",
       "5930    The Concubine / Royal Concubine: Concubine of ...\n",
       "Name: name, Length: 699, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
